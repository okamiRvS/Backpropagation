{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(1000, 2)\n",
    "y = 50 * np.exp(np.sin(X)) # too difficult?\n",
    "#y = 15 * np.sin(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670, 2), (670, 2))"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = 2\n",
    "hid_1_size = 20\n",
    "hid_2_size = 15\n",
    "hid_3_size = 5\n",
    "out_size = 2\n",
    "\n",
    "sizes = [in_size, hid_1_size, hid_2_size, hid_3_size, out_size]\n",
    "\n",
    "# in_size = 2\n",
    "# hid_2_size = 5\n",
    "# hid_3_size = 3\n",
    "# out_size = 2\n",
    "\n",
    "# sizes = [in_size, hid_2_size, hid_3_size, out_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_l1 | Layer 1, with index 0\n",
      "[[0.03921054 0.02523183]\n",
      " [0.27155029 0.46185344]\n",
      " [0.72624328 0.4748717 ]\n",
      " [0.90405082 0.0352198 ]\n",
      " [0.18066062 0.33851449]\n",
      " [0.57749619 0.85273616]\n",
      " [0.35020195 0.26798868]\n",
      " [0.06188917 0.82130348]\n",
      " [0.37966644 0.5715502 ]\n",
      " [0.98355542 0.00159457]\n",
      " [0.14545014 0.77911099]\n",
      " [0.80512749 0.76924712]\n",
      " [0.53699889 0.97885698]\n",
      " [0.39618456 0.6019437 ]\n",
      " [0.063369   0.40985745]\n",
      " [0.72250009 0.23873884]\n",
      " [0.94382759 0.68678337]\n",
      " [0.28757538 0.76899892]\n",
      " [0.08316477 0.97477442]\n",
      " [0.04928526 0.93345589]]\n",
      "\n",
      "\n",
      "W_l2 | Layer 2, with index 1\n",
      "[[2.52853878e-01 7.57824108e-01 7.36994331e-05 2.54240089e-01\n",
      "  7.49100607e-01 5.32336071e-01 1.14952150e-01 3.93629746e-01\n",
      "  3.75549355e-01 5.68162244e-01 6.67977072e-01 8.40830242e-01\n",
      "  4.97231397e-01 3.92021717e-01 1.43976534e-01 8.04822965e-01\n",
      "  7.13370405e-01 4.08677397e-01 5.18432310e-01 6.65182844e-01]\n",
      " [1.64805590e-01 2.71977944e-02 3.17503699e-01 5.95585020e-01\n",
      "  4.86606091e-01 6.92554627e-01 8.19689806e-01 4.88442467e-01\n",
      "  1.34267024e-01 8.50628000e-01 5.74990327e-01 7.39937481e-01\n",
      "  7.04664654e-01 9.68211771e-01 2.95307322e-01 7.05306773e-01\n",
      "  3.65676333e-01 3.95410721e-01 2.30594637e-01 3.44010176e-01]\n",
      " [9.48296752e-01 2.92570847e-01 2.45990606e-01 5.83137978e-01\n",
      "  2.58035957e-01 4.73385726e-01 8.34176257e-01 2.30400314e-01\n",
      "  4.26691412e-01 6.10489735e-01 5.45628925e-01 9.74723237e-01\n",
      "  6.80370254e-01 7.39946242e-01 9.66955948e-01 4.14438025e-01\n",
      "  3.55379815e-01 4.38624298e-02 1.84204307e-01 2.37189632e-01]\n",
      " [1.83504467e-01 7.54783893e-01 5.35882981e-01 6.67633801e-01\n",
      "  8.20462161e-01 2.30773941e-01 3.25923940e-01 7.08360267e-01\n",
      "  3.92758946e-01 2.92709401e-02 4.34955219e-01 9.08273086e-01\n",
      "  4.09021512e-01 3.32248916e-01 9.89525083e-01 6.44415564e-01\n",
      "  3.65998026e-01 1.02019531e-01 7.87849445e-01 7.08074933e-01]\n",
      " [9.21915799e-01 2.17275630e-01 1.14924350e-01 7.24072526e-01\n",
      "  2.03395842e-01 1.76103838e-01 3.19807335e-01 8.16825141e-01\n",
      "  5.39536605e-01 4.58503551e-02 4.63894675e-01 6.83979611e-01\n",
      "  5.38368438e-01 5.72450218e-01 2.24777328e-01 8.47739332e-01\n",
      "  5.61398718e-01 7.13246013e-01 9.81864217e-01 4.28198658e-01]\n",
      " [8.81066613e-01 7.28101394e-03 3.34072926e-02 5.90279922e-01\n",
      "  3.11449396e-01 2.48276567e-01 2.77935357e-01 3.18402935e-01\n",
      "  7.28947696e-01 5.69195972e-01 7.89035973e-01 8.30196580e-01\n",
      "  8.42934859e-01 4.14644149e-01 4.21273396e-01 9.26265880e-01\n",
      "  6.61763595e-01 8.04671840e-02 5.42186954e-01 3.56007260e-01]\n",
      " [9.87434990e-01 1.36554065e-02 6.12180873e-01 7.23623094e-01\n",
      "  2.88906771e-01 9.73641518e-01 8.59536627e-01 9.15652841e-01\n",
      "  1.92320594e-02 5.69872151e-01 2.94650242e-01 8.49028635e-01\n",
      "  6.32849657e-01 5.38877004e-01 1.14588170e-01 5.40222805e-01\n",
      "  6.31904146e-01 9.55912309e-01 5.85051010e-01 9.67400602e-01]\n",
      " [9.61606116e-01 6.50200336e-01 5.05907984e-01 4.66021744e-01\n",
      "  8.90378561e-01 2.82566830e-02 1.13808198e-01 1.02071729e-01\n",
      "  7.56935325e-01 3.39651024e-01 6.37968545e-01 6.03782904e-01\n",
      "  3.85827970e-01 5.31567722e-01 6.45138534e-01 9.40950330e-01\n",
      "  5.75634073e-01 6.14367512e-01 6.78558177e-02 9.52215815e-01]\n",
      " [5.28081928e-01 8.01273420e-01 5.02910631e-02 4.20910136e-01\n",
      "  2.56975459e-01 2.66975899e-01 7.91453730e-01 6.23866725e-01\n",
      "  4.39745312e-01 1.05857396e-02 9.64927943e-01 9.62023253e-01\n",
      "  2.17552210e-01 4.13463723e-02 5.30199363e-01 9.51410815e-01\n",
      "  9.10395846e-01 5.84662864e-01 3.03548851e-01 3.29960884e-01]\n",
      " [8.97913551e-01 4.91784036e-01 1.31116229e-01 2.48425476e-01\n",
      "  2.76794901e-01 1.23546685e-01 4.63044382e-01 9.16050908e-01\n",
      "  6.68782543e-01 7.24739242e-02 5.49481781e-03 2.76247667e-01\n",
      "  3.62692935e-01 7.76749669e-01 9.67005524e-01 3.87567173e-01\n",
      "  6.86690030e-01 9.94901907e-01 7.45666584e-01 6.36189549e-01]\n",
      " [7.80748542e-02 3.23215201e-01 9.13392158e-01 2.01005482e-01\n",
      "  8.43590359e-01 6.96323685e-01 3.66324371e-01 5.29174270e-01\n",
      "  5.42806469e-01 7.14053785e-01 5.16555941e-01 1.33075990e-01\n",
      "  7.73454672e-01 4.06272497e-01 9.63093890e-01 2.83513782e-01\n",
      "  2.63078780e-01 3.33507396e-01 5.72317016e-01 8.94869740e-01]\n",
      " [1.76281640e-01 2.79678798e-01 5.81679843e-01 4.54334242e-01\n",
      "  4.47322887e-01 8.20734262e-01 9.23878303e-01 4.81306966e-01\n",
      "  6.87351795e-01 8.01058711e-01 5.18366410e-01 2.94316409e-01\n",
      "  6.38084598e-01 5.85109100e-01 9.01562820e-01 5.24070368e-02\n",
      "  9.10131387e-01 5.34432028e-01 1.56761160e-02 3.44702179e-01]\n",
      " [7.24333564e-01 4.88433088e-01 9.80159037e-01 4.22610074e-01\n",
      "  3.26635230e-01 8.21671934e-01 5.47906699e-01 6.82326579e-01\n",
      "  8.05702338e-01 6.71427546e-01 4.22407495e-01 1.24796448e-01\n",
      "  5.80248167e-01 8.97433327e-01 4.18892427e-01 9.10725235e-01\n",
      "  5.03527820e-01 6.20841562e-01 8.32988476e-01 5.64597110e-01]\n",
      " [9.09693393e-02 9.80979401e-01 2.45849302e-01 7.10505329e-01\n",
      "  5.05113439e-01 4.78772637e-01 2.43940819e-01 7.22150766e-01\n",
      "  1.12788265e-01 9.90453309e-01 8.45373537e-01 5.34508940e-01\n",
      "  4.24552956e-01 2.86464632e-01 5.01591471e-01 8.79417462e-01\n",
      "  2.75006401e-01 5.00537459e-01 2.34549902e-01 3.37149114e-01]\n",
      " [1.90260509e-01 9.90539194e-01 5.71497446e-01 7.32815124e-01\n",
      "  9.82499135e-02 3.66117550e-01 8.92639803e-01 8.44383264e-02\n",
      "  1.65483228e-01 6.25417610e-01 6.22788994e-01 8.38227044e-01\n",
      "  9.35492764e-01 1.41986475e-01 2.59373819e-01 4.27461406e-01\n",
      "  9.03285521e-04 6.98143030e-02 2.26491278e-01 4.81101964e-01]]\n",
      "\n",
      "\n",
      "W_l3 | Layer 3, with index 2\n",
      "[[0.25152274 0.87668189 0.32427288 0.92462281 0.97478726 0.44986153\n",
      "  0.22712882 0.29166613 0.77633368 0.27334971 0.38058287 0.47857586\n",
      "  0.57511112 0.99610044 0.23220976]\n",
      " [0.3534237  0.26289118 0.36111344 0.10080452 0.35980977 0.88786503\n",
      "  0.29858985 0.37193478 0.94447416 0.728379   0.51673871 0.77719273\n",
      "  0.12317965 0.46449035 0.11823613]\n",
      " [0.23361815 0.14186726 0.36180124 0.38163932 0.94730858 0.26412573\n",
      "  0.47242885 0.8113794  0.81561759 0.75034319 0.28783376 0.49497162\n",
      "  0.1862116  0.18839952 0.43584121]\n",
      " [0.73859222 0.52658426 0.88668322 0.8309088  0.03160544 0.56841904\n",
      "  0.60916126 0.96157514 0.02323663 0.53110377 0.20478136 0.05366291\n",
      "  0.58748852 0.77260414 0.77486545]\n",
      " [0.03028841 0.4069464  0.04450963 0.24783865 0.1928807  0.21518258\n",
      "  0.33911841 0.27741804 0.96227991 0.35240712 0.89417252 0.18104167\n",
      "  0.76374687 0.06134554 0.46276123]]\n",
      "\n",
      "\n",
      "W_l4 | Layer 4, with index 3\n",
      "[[0.00551044 0.81029076 0.95048604 0.03510737 0.93384636]\n",
      " [0.77385389 0.35886158 0.90887655 0.29625727 0.40929531]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "W = []\n",
    "\n",
    "for i in range(1, len(sizes)):\n",
    "    W.append(np.random.rand(sizes[i], sizes[i-1]))\n",
    "    print(f\"W_l{i} | Layer {i}, with index {i-1}\")\n",
    "    print(W[i-1])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_l1 | Layer 1, with index 0:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "a_l1 | Layer 1, with index 0:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "z_l2 | Layer 2, with index 1:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "a_l2 | Layer 2, with index 1:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "z_l3 | Layer 3, with index 2:\n",
      "[0. 0. 0. 0. 0.]\n",
      "a_l3 | Layer 3, with index 2:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "z_l4 | Layer 4, with index 3:\n",
      "[0. 0.]\n",
      "a_l4 | Layer 4, with index 3:\n",
      "[0. 0.]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = []\n",
    "a = []\n",
    "\n",
    "\n",
    "for i in range(1, len(sizes)):\n",
    "    z.append(np.zeros(sizes[i]))\n",
    "    a.append(np.zeros(sizes[i]))\n",
    "    print(f\"z_l{i} | Layer {i}, with index {i-1}:\")\n",
    "    print(z[i-1])\n",
    "    print(f\"a_l{i} | Layer {i}, with index {i-1}:\")\n",
    "    print(a[i-1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(xi, log=False):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # Input\n",
    "        if log: print(\"Input x:\")\n",
    "        x = np.array([xi]).T\n",
    "        if log: print(x, \"\\n\")\n",
    "\n",
    "        z[0] = W[0] @ x\n",
    "        a[0] = 1 / (1 + np.exp(-z[0]))\n",
    "        if log: print(f\"W_l{1}\", \"\\n\", W[0], \"\\n\")\n",
    "        if log: print(f\"z_l{1}\", \"\\n\", z[0], \"\\n\")\n",
    "        if log: print(f\"a_l{1}\", \"\\n\", a[0], \"\\n\")\n",
    "\n",
    "        # Hidden layers, and output\n",
    "        for i in range(1, len(sizes)-1):\n",
    "\n",
    "            if log: print(f\"Layer {i+1}:\")\n",
    "            z[i] = W[i] @ a[i-1]\n",
    "\n",
    "            if i != len(sizes)-2:\n",
    "                a[i] = 1 / (1 + np.exp(-z[i]))\n",
    "                if log: print(f\"W_l{i+1}\", \"\\n\", W[i], \"\\n\")\n",
    "                if log: print(f\"z_l{i+1}\", \"\\n\", z[i], \"\\n\")\n",
    "                if log: print(f\"a_l{i+1}\", \"\\n\", a[i], \"\\n\")\n",
    "            else:\n",
    "                a[i] = z[i]\n",
    "                if log: print(f\"W_l{i+1}\", \"\\n\", W[i], \"\\n\")\n",
    "                if log: print(f\"z_l{i+1}\", \"\\n\", z[i], \"\\n\")\n",
    "                if log: print(\"y\", \"\\n\", a[i], \"\\n\")                \n",
    "\n",
    "        return a[len(sizes)-2]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def loss_MSE(x, t, log=False):\n",
    "    # MSE\n",
    "    if log: print(\"t\" \"\\n\", t, \"\\n\")\n",
    "\n",
    "    try:\n",
    "        MSE = 0.5 * ( (t[0] - x[0])** 2 + (t[1] - x[1])** 2 )\n",
    "        return MSE\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def backward(t):\n",
    "\n",
    "    # Initialization\n",
    "    W_grad = []\n",
    "    for w in W:\n",
    "        W_grad.append(np.zeros_like(w))\n",
    "\n",
    "    delta = []\n",
    "    for i in range(1, len(sizes)):\n",
    "        delta.append(np.zeros(sizes[i]))\n",
    "\n",
    "    # -------------------------------\n",
    "    # Final LAYER\n",
    "    # --> compute delta\n",
    "    out_size = sizes[-1]\n",
    "    hid_last_size = sizes[-2]\n",
    "    L = len(sizes)-2\n",
    "    for i in range(out_size):\n",
    "        # delta^L_i = y_i - t_1\n",
    "        delta[L][i] = a[L][i] - t[i]\n",
    "\n",
    "    # --> compute W_grad\n",
    "    for i in range(out_size):\n",
    "        for j in range(hid_last_size):\n",
    "            W_grad[L][i,j] = delta[L][i] * a[L-1][j]\n",
    "\n",
    "    # -------------------------------\n",
    "    for l in range(L, 0, -1):\n",
    "        # LAYER 1\n",
    "        # --> compute delta\n",
    "        next_size = sizes[l+1]\n",
    "        prev_size = sizes[l]\n",
    "        for k in range(prev_size):\n",
    "            acc = 0\n",
    "            for i in range(next_size):\n",
    "                acc += delta[l][i] * W[l][i,k] * a[l-1][k] * (1 - a[l-1][k])\n",
    "            delta[l-1][k] = acc\n",
    "\n",
    "        # --> compute W_grad\n",
    "        pre_prev_size = sizes[l-1]\n",
    "        for i in range(prev_size):\n",
    "            for j in range(pre_prev_size):\n",
    "                if l!=1:\n",
    "                    W_grad[l-1][i,j] = delta[l-1][i] * a[l-2][j]\n",
    "                else:\n",
    "                    W_grad[l-1][i,j] = delta[l-1][i] * x[j]\n",
    "\n",
    "    # UPDATE WEIGHTS\n",
    "    mu = 0.00001\n",
    "    for idx, w_grad in enumerate(W_grad):\n",
    "        W[idx] = W[idx] - mu * w_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, \t Test loss: [6183.55315267], \t Train loss: [6272.83229318]\n",
      "Epoch: 10, \t Test loss: [3341.81627543], \t Train loss: [3414.39899016]\n",
      "Epoch: 20, \t Test loss: [1888.60341109], \t Train loss: [1949.22778941]\n",
      "Epoch: 30, \t Test loss: [1147.04318359], \t Train loss: [1199.11044133]\n",
      "Epoch: 40, \t Test loss: [769.23671913], \t Train loss: [815.18183597]\n",
      "Epoch: 50, \t Test loss: [577.131988], \t Train loss: [618.69733353]\n",
      "Epoch: 60, \t Test loss: [479.71462684], \t Train loss: [518.1467785]\n",
      "Epoch: 70, \t Test loss: [430.50111281], \t Train loss: [466.69187822]\n",
      "Epoch: 80, \t Test loss: [405.77409905], \t Train loss: [440.36146233]\n",
      "Epoch: 90, \t Test loss: [393.44769844], \t Train loss: [426.88805504]\n",
      "Epoch: 100, \t Test loss: [387.3740121], \t Train loss: [419.99385096]\n",
      "Epoch: 110, \t Test loss: [384.43341325], \t Train loss: [416.4662914]\n",
      "Epoch: 120, \t Test loss: [383.04844075], \t Train loss: [414.66143483]\n",
      "Epoch: 130, \t Test loss: [382.42542402], \t Train loss: [413.73805309]\n",
      "Epoch: 140, \t Test loss: [382.16792429], \t Train loss: [413.26568676]\n",
      "Epoch: 150, \t Test loss: [382.08001655], \t Train loss: [413.02407393]\n",
      "Epoch: 160, \t Test loss: [382.06640825], \t Train loss: [412.90051255]\n",
      "Epoch: 170, \t Test loss: [382.08188943], \t Train loss: [412.83733871]\n",
      "Epoch: 180, \t Test loss: [382.10586722], \t Train loss: [412.80505059]\n",
      "Epoch: 190, \t Test loss: [382.12962238], \t Train loss: [412.78855591]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "for ep in range(EPOCHS):\n",
    "    for i in range(X_train.shape[0]):\n",
    "        target = y_train[i]\n",
    "        out = forward(X_train[i], False)\n",
    "        loss = loss_MSE(out, target)\n",
    "        backward(target)\n",
    "\n",
    "    if ep%10==0:\n",
    "        loss = 0\n",
    "        for j in range(X_train.shape[0]):\n",
    "            target = y_train[j]\n",
    "            out = forward(X_train[j])\n",
    "            loss += loss_MSE(out, target)\n",
    "        l_train = loss / X_train.shape[0]\n",
    "\n",
    "        loss = 0\n",
    "        for j in range(X_test.shape[0]):\n",
    "            target = y_test[j]\n",
    "            out = forward(X_test[j])\n",
    "            loss += loss_MSE(out, target)\n",
    "        l_test = loss / X_test.shape[0]\n",
    "\n",
    "        print(f\"Epoch: {ep}, \\t Test loss: {l_test}, \\t Train loss: {l_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input \t0.23277267218111208 0.3106292182913063\n",
      "target \t62.972574544472614 67.87588434172426\n",
      "out \t82.23956058130544 81.33990522338149\n",
      "loss \t[276.24830462] \n",
      "\n",
      "input \t0.8020685238956139 0.37441398387974\n",
      "target \t102.59802828619908 72.07809465432801\n",
      "out \t82.23976223274947 81.34010379491708\n",
      "loss \t[250.12190501] \n",
      "\n",
      "input \t0.9003674516042256 0.9832748650501553\n",
      "target \t109.46208939593427 114.93193607177265\n",
      "out \t82.239880562235 81.34022029193879\n",
      "loss \t[934.72601141] \n",
      "\n",
      "input \t0.40044853473592334 0.6658713983098399\n",
      "target \t73.8365920824816 92.73700851416619\n",
      "out \t82.23975694868992 81.34009857067845\n",
      "loss \t[100.25136801] \n",
      "\n",
      "input \t0.47938454938918806 0.9148630878333829\n",
      "target \t79.3014324358031 110.44328122822978\n",
      "out \t82.23982596537022 81.3401665260223\n",
      "loss \t[427.81272095] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "for i in range(5):\n",
    "    out = forward(X_test[i])\n",
    "    loss = loss_MSE(out, y_test[i])\n",
    "    print(f\"input \\t{X_test[i][0]} {X_test[i][1]}\")\n",
    "    print(f\"target \\t{y_test[i][0]} {y_test[i][1]}\")\n",
    "    print(f\"out \\t{out[0][0]} {out[1][0]}\")\n",
    "    print(f\"loss \\t{loss} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f7e374ee5e09e3e1c64a32e01379f0a0a71f66221bd3efaa81b204d4a8f2076c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
